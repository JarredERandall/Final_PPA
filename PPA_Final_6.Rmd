---
title: "FairBnB"
output: html_document
date: "2023-12-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE, class.source = 'fold-show'}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidycensus)
library(sf)
library(stargazer)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(kableExtra)
library(grid)
library(viridisLite)
library(viridis)
library(gridExtra)
library(jtools)
library(ggcorrplot) 
library(corrr)      
library(kableExtra)
library(jtools)     
library(ggstance) 
library(ggpubr)   
library(broom.mixed) 
options(scipen = 999)


root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

census_api_key("a6d692af505769f28e39a3ac16b7dcbacb1dad58", overwrite = TRUE)

palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")

palette6 <- c("#25CB10", "#5AB60C", "grey40",   "grey40", "#FA7800")

airbnb_color <- c("#FF5A5F")

theme_update(plot.title = element_text(hjust = 0.5))
```

# Intro

# Data
## Data Import
```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
listings <- read.csv("/Users/nohman/Documents/GitHub/PPA_Final_Airbnb/Data/Airbnb/listings.csv")

nhoods <- st_read("/Users/nohman/Documents/GitHub/PPA_Final_Airbnb/Data/Airbnb/neighbourhoods.geojson")

attraction_distance <- read.csv("/Users/nohman/Documents/GitHub/Final_PPA/Data/Airbnb/distance_attrac.csv")

listings_details <- read.csv("/Users/nohman/Documents/GitHub/PPA_Final_Airbnb/Data/Airbnb/listings_details.csv")

income <- read.csv("/Users/nohman/Documents/GitHub/Final_PPA/Data/Amsterdam_income.csv")

census <- read.csv("/Users/nohman/Documents/GitHub/Final_PPA/Data/final_census.csv")
```

## Data Wrangling
``` {r joined_nhood sf}
# Joining data sets, converting to crs
attraction_distance <- attraction_distance %>% transform(zipcode = as.character(zipcode))

listings <- left_join(listings, listings_details, by = "id", suffix=c("", ".y")) %>% select(-ends_with(".y"))

listings <- left_join(listings, attraction_distance, by = "zipcode", suffix=c("", ".y")) %>% select(-ends_with(".y")) %>% st_as_sf(coords = c('longitude', 'latitude'), crs = 4326)  %>%
  st_transform(st_crs(nhoods))

listings <- st_join(listings, nhoods, join = st_within, suffix=c("", ".y")) %>% select(-ends_with(".y"))

# Converting census columns into numeric
for (i in sequence(33,3,1)) {
  census[[i]] <- as.numeric(census[[i]])
}

# Grouping and summarizing census data per zip code
census <- census %>% group_by(PostalCode) %>% summarize(married = sum(Married, na.rm = TRUE), 
                                                        migration = sum(Persons_with_a_migration_background, na.rm =     TRUE),
                                                        vio_sex_crimes = sum(Violentandsexualcrimes, na.rm = TRUE),
                                                        cafes = mean(cafe_Within_1_km, na.rm = TRUE),
                                                        restaurants = mean(restaurants_Within_1_km, na.rm = TRUE),
                                                        hotels = mean(hotels_Within_5_km, na.rm = TRUE),
                                                        road = mean(Distance_to_main_road_entrance, na.rm = TRUE),
                                                        train = mean(Distance_to_train_station, na.rm = TRUE)) %>%
                                             filter(!PostalCode %in% (".")) 


# Formatting zip code correctly and changing column name
census$PostalCode <- str_extract(census$PostalCode, "^.{4}")

listings$zipcode <- str_extract(listings$zipcode, "^.{4}")  

colnames(census)[1] <- "zipcode"

# Joining listings with zip codes
listings <- left_join(listings, census, by = "zipcode")
```

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Adding the number of amenities per listing
amenities_count <- as.integer(str_count(listings$amenities, ","))
amenities_count <- ifelse(amenities_count > 0, amenities_count + 1, amenities_count)

listings <- cbind(listings, amenities_count) 

# Converting columns weekly price, monthly price, cleaning fee, and security deposit to numeric values
for (i in sequence(6, 67, 1)) {
  listings[[i]] <- gsub("^.{0,1}", "", listings[[i]])
  listings[[i]] <- as.numeric(ifelse(nchar(listings[[i]]) == 0, "0", listings[[i]]) %>% str_replace(",", ""))
}

# Remove rows with no rent data
listings <- listings %>% filter(weekly_price > 0 | monthly_price > 0)

# Calculating a daily price from either weekly or monthly price
listings$daily_price <- ifelse(listings$weekly_price > 0, listings$weekly_price / 7, listings$monthly_price / 30)

# Filtering for outliers
listings <- listings %>% filter(daily_price > 0 & daily_price < 1500)

# Selecting a list of all relevant variables
var <- c("zipcode", "daily_price", "room_type", "host_is_superhost", "host_identity_verified", "accommodates", "beds", "bed_type", "cancellation_policy", "number_of_reviews", "property_type", "bathrooms", "bedrooms", "amenities_count", "review_scores_rating", "has_availability", "guests_included", "security_deposit", "cleaning_fee", "extra_people","neighbourhood", "availability_30", "weekly_price", "monthly_price", "near_ATTRAC", "near_museum", "near_Performing_arts", "married", "migration", "vio_sex_crimes", "cafes", "restaurants", "hotels", "road", "train")

listings <- listings %>% select(all_of(var)) 


# Removing NA values for important regression variables. Annotate how many we lost (Jarred)
listings <- listings %>% drop_na(cleaning_fee, security_deposit)
```

## Exploratory Data Analysis
### Dependent Variable
```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
variables_to_summarize <- c("daily_price","room_type","near_ATTRAC", "k_nearest_price",
                            "number_of_reviews","property_type", "bathrooms", "bedrooms",
                            "review_scores_rating", "cancellation_policy", "host_identity_verified",
                            "accommodates", "beds", "bed_type", "host_is_superhost", "cleaning_fee",
                            "security_deposit", "extra_people", "zipcode", "availability_30", "neighbourhood")


summary_stats <- descr(listings[, variables_to_summarize], stats = "common")  
summary_table <- t(summary_stats)


rounded_summary <- t(apply(summary_table, 1, function(x) {
  if (all(is.numeric(x))) {
    return(round(x, 2))
  } else {
    return(x)
  }
}))

# Create the table using kableExtra
rounded_summary %>%
  kbl(caption = "Summary Statistics") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```


```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Show a of the unlogged daily price (Jarred) 
gghistogram(
  data = listings, x = "daily_price", 
  add = "mean", rug = TRUE,
  fill = airbnb_color) +
  labs(title = "Daily AirBnB Price Distribution Amsterdam", caption = "Fig.1") +
   xlab("Daily Price") +
   ylab("Count") 
```
We constructed our dependent variable, the daily price of renting an AirBnB in Amsterdam, by dividing the week price by seven or the monthly price by thirty. Since longer bookings usually include greater discounts, and since a week is shorter than a month, we preferred calculating the daily price from the weekly price, and only if the weekly price was not available, we would normalize the monthly price to a daily price.

When visualizing the daily price, we see a heavy right-skew. Since our model will employ OLS regression, normalized variables are preferred since they can increase the performance and significance of the model.

We hence continue to log transform our dependent variable.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Log price by Property Type (Jarred) 
listings$daily_price <- log(listings$daily_price)

gghistogram(
  data = listings, x = "daily_price", 
  add = "mean", rug = TRUE,
  fill = airbnb_color) +
  labs(title = "Daily AirBnB Price Distribution Amsterdam", caption = "Fig.1") +
   xlab("Daily Price") +
   ylab("Count") 

```
The log transformed daily price shows an approximate normal distribution and will therefore be used as dependent variable for the regression model.

### Independent Variables (Predictors)
We want to build a hedonic housing price model that includes 1) internal features of the house, the 2) spatial process, 3) demographics, 4) centrality, and 5) infrastructural variables. 

To pick meaningful predictors, we set up a correlation matrix and observe values that have a high correlation with our dependent variable. Note that it doesn't matter if the correlation is negative or positive- high values in both contain potentially valuable information for the model.

In the next subsections, we will go through each of these points, explain which features we engineered, and whether the correlation matrix gives us a reason to include these features in our model.
```{r map_1}
# Calculating averages per neighborhood
avg_nhood <- listings %>%
  group_by(neighbourhood) %>%
  summarize(avg_road = mean(road, na.rm = TRUE), 
            avg_cafes = mean(cafes, na.rm = TRUE), 
            avg_restaurants = mean(restaurants, na.rm = TRUE), 
            avg_hotels = mean(hotels, na.rm = TRUE), 
            avg_train=mean(train, na.rm = TRUE), 
            avg_price = exp(mean(daily_price, na.rm = TRUE)),
            avg_attrac = mean(near_ATTRAC, na.rm = TRUE),
            avg_amenities = mean(amenities_count, na.rm = TRUE),
            avg_sex_crimes = mean(vio_sex_crimes, na.rm = TRUE),
            avg_migration = mean(migration, na.rm = TRUE),
            avg_married = mean(married, na.rm = TRUE))

neighbourhood_boundaries <- nhoods

# Adding neighborhood boundary info
neighbourhood_boundaries$neighbourhood <- as.character(neighbourhood_boundaries$neighbourhood)
avg_nhood$neighbourhood <- as.character(avg_nhood$neighbourhood)

merged_data_sf <- st_join(neighbourhood_boundaries, avg_nhood)

# Looping to save a map for each variable inside. We save the ggplots in the object "maps"
maps <- lapply(c("avg_price", "avg_road", "avg_cafes", "avg_restaurants", "avg_hotels", "avg_train", "avg_attrac", "avg_amenities", "avg_sex_crimes", "avg_migration", "avg_married"), function(i) {  
  ggplot()+
  geom_sf(data = merged_data_sf, aes(fill = (avg_nhood[[i]])))+
  theme_void()})

maps[[1]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
corr_vars <- 
  select_if(st_drop_geometry(listings), is.numeric) %>% na.omit()

corr_vars <- select_if(st_drop_geometry(listings), is.numeric) %>%
  na.omit()

corr_vars <- corr_vars %>% select(-guests_included)

corr_vars %>% 
  correlate() %>% 
  autoplot() +
  geom_text(aes(label = round(r,digits=2)),size = 2)
```
One interesting observation from the correlation matrix upfront is that daily price is much more correlated with weekly price (0.87) than with monthly price (0.4) implying that it is likely that for most daily price calculations, we actually had a weekly price value and didn't have to use the monthly price to infer the daily price. This is good for the model for reasons related to long-term rental discounts as mentioned above.

#### Hedonic Variables
#### Numeric Hedonic Predictors
As for hedonic variables, we used the predictors in the given data set and engineered a new feature called amenities count, to which we will get later. 

As expected, the correlation matrix shows that number of accommodates (0.55), bedrooms (0.54), beds (0.53), and bathrooms (0.33) are the leading four values. What is interesting is that all of these predictors are essentially proxies for the size of a listing. Since we know that usually, square feet is among the top housing price predictors, but we unfortunately don't have that data for most of our observations, it only makes sense that these "best proxies" have the highest absolute correlation with the daily price. 

 *Table number of houses with and without sqft*
 
Another interesting observation is that the number of bathrooms is less positively correlated with daily price as the other three predictors- a result that is counter-intuitive since most of our work was done in the North American context. Upon some research, there is an easy explanation for that: European houses, on average, simply have fewer bathrooms, even when normalized on a per square feet basis (https://www.theatlantic.com/ideas/archive/2020/01/why-do-american-houses-have-so-many-bathrooms/605338/).

The remaining hedonic variables that show some correlation are the cleaning fee (0.39) and the security deposit (0.2). With regard to cleaning fees, it makes sense that more expensive listings will charge higher fees as they have likely more expensive interieur and a greater area to clean. 

What is surprising, however, is that the security deposit is only half as strongly correlated with listing price as the cleaning fee. Intuitively, the strength of correlation between cleaning fee and security deposit should approximately match.

There are several explanations as to why there is this difference. Firstly, if the host sets no security deposit amount himself, AirBnB will calculate itself an automated rate that takes 60% of a nights fee times the number of nights rented. This, however, is capped at 1000$. This implies that expensive listings with no host set price cap are only requiring a rather low security deposit. Another reason is likely that high security deposits make a listing less likely to be booked by increasing the barriers to book the apartment. A host tries to make his listing attractive, and listings that have good features and are well situated with rather low security deposits are more likely to be booked than similar apartments with rather high security deposits.

*Graph with apartments greater than 100$ per night and their average security deposit vs apartments with less than and their average*

Surprisingly, the engineered feature amenities count which counts the number of amenities in a listing is only weakly correlated with the price. This is because users are rather inconsistent in naming all features, and many low priced homes have many of the features like a couch, TV, etc. The only way to discriminate an expensive from an inexpensive listing could be "special features" like pools, gaming rooms, and so forth - but in a count, a pool and a TV would both simply add one the count.

#### Non-Numeric Hedonic Predictors
As for non-numeric hedonic predictors, we look at the property type. This is an obvious predictor to pick since shared rooms, for instance, are likely to be much less expensive that whole houses.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
colors <- rainbow(length(unique(listings$neighbourhood)))

faded_colors2 <- adjustcolor(colors, alpha.f = 0.6) 

ggplot(data = listings, aes(x = room_type, y = exp(daily_price), fill = room_type)) + 
  geom_boxplot() +
  scale_fill_manual(values = faded_colors2, name = "Listing Type") + 
  theme_minimal() +
  labs(y = "Logarithm of Price", x = "", title = "Logarithm of Daily Price by Listing Type") +
  theme(
    axis.text.x = element_blank(), 
    legend.position = "bottom", 
    legend.title.align = 0.5, 
    plot.title = element_text(hjust = 0.5) 
  ) +
  guides(fill = guide_legend(nrow =1, byrow = TRUE, title.position = "top")) 
```

#### Spatial process
A regression run purely on hedonic factors results in an $R^2$ of 0.4. This value is relatively low, and one could argue that including the spatial process could increase it significantly. 

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Log price by neighborhood (Jarred) 
listings$neighbourhood <- factor(listings$neighbourhood)

faded_colors <- adjustcolor(colors, alpha.f = 0.4) 

ggplot(data = listings, aes(x = neighbourhood, y = exp(daily_price), fill = neighbourhood)) + 
  geom_boxplot() +
  scale_fill_manual(values = faded_colors, name = "Neighborhoods") + 
  theme_minimal() +
  labs(y = "Logarithm of Price", x = "", title = "Logarithm of Daily Price by Neighbourhood.") +
  theme(
    axis.text.x = element_blank(), 
    legend.position = "bottom", 
    legend.title.align = 0.5, 
    plot.title = element_text(hjust = 0.5) 
  ) +
  guides(fill = guide_legend(nrow = 5, byrow = TRUE, title.position = "top")) 
```
We clearly see that neighbourhoud can explain some of the daily price. But we also see that the effect is not as strong as we would see it in some US cities. 

Additionally, we see that central districts like Centrum West are usually more highly priced than neighbourhods farther away. We will therefore engineer the distance-to-center vs daily price relation in a later section.

Adding the neighourhoud effects and even the k-nearest neighbors only increases $R^2$ to 0.5. What this implies is that neighbourhood and k-nearest can help explain a significant portion of the variance in price, but by far not most of it. In simple terms, our model is missing vital information, and this only makes sense: K-nearest are a better predictor for very densely populated housing price predictions since we can be assured that we will have very immediate neighbors with likely the same features. 

However, our data set is not as dense, meaning that our k-nearest observations are quite far away, and that as a consequence, we could even switch between neighbourhouds. Additionally, we are missing the square feet size of each apartment, a core predictor for each pricing prediction. 

*Add average distance to k nearest neighbors (use spatstats package) nndist(listings, 5) spatstats OR say that changing k nearest from 5 to 20 doesn't make a big difference in the model -> low spatial process -> more hedonic variables for prediction*

Given the above observations, we therefore tried to come up with demographic and infrastructural feature engineering to improve the model.

#### Demographics
The idea behind demographic features is that they could contain information on the AirBnB price as customers surely are concerned about their safety and social environment of their AirBnB.

We therefore assume two things: First, that customers do good research before committing to an AirBnB and are willing to pay a premium for more safe neighbourhoods, and secondly, that these demographic features are not evenly distributed in the suburbs, but show peaks and lows depending on whether a neighborhood is good and therefore highly priced, or not.

With this in mind, we imported data on the percentage of migrants, number of violent sex crimes, and the proportion of married population for each listing. It is rather surprising to see that these demographics don't really have an effect on the correlation. 

As explained above, one reason for this could be that all some of these factors are rather distributed throughout expensive and non-expensive listings in the city and therefore would not help our model discriminate high priced from low priced listings.

Support for this comes from the map comparing neighbourhoods where crimes occur versus neighbourhoods with high proprtion of married households.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# 9 crimes, 10 migrants, 11 married
maps[[9]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```
We first observe that there is a hotspot for crimes in the same area in which there are many cafes, as we had previously predicted.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# 9 crimes, 10 migrants, 11 married
maps[[3]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```
We then see that the areas with high migrant population are not those where most crimes occur, and that areas with high migrant population also have high marriage rates.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# 9 crimes, 10 migrants, 11 married
maps[[10]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# 9 crimes, 10 migrants, 11 married
maps[[11]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```
However, the whole central-west side of the city has quite high marriage rates, implying that if our hypothesis that most expensive apartments are in the center is true, marriage would not be as strong a predictor as we'd wish.

#### Centrality
European cities are generally more center focused. This is to say that there is always a central part of the town in which most commerce, infrastructure, but also tourism happens. The areas around the center are rather constructed such that they cater toward the central district.

With all these properties, the assumption that tourists will be willing to pay a premium to live close to central makes sense. And even though a great public transportation network may attenuate that willingness, there still should be a visible trend.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Distance to city center (why are there NA's?)
MRB <- multipleRingBuffer(st_union(listings %>% filter(neighbourhood == "Centrum-West")), 11000, 200)

listings <- st_join(listings, MRB, join = st_intersects) %>% 
            st_sf()

listings <- listings %>% mutate(distance = ifelse(listings$neighbourhood == "Centrum-West", 0, distance))

# Map of MRB and data points
ggplot() + geom_sf(data = MRB) + geom_sf(data = listings)

# Distance vs price plot
ggplot() +  geom_line(data = listings %>% filter(distance < 6000), 
                  aes(x = distance, 
                      y = exp(daily_price)), 
                      stat = "summary", 
                      fun = mean) +
         labs(title = "Median Rent as Function of Distance in Miles",
              caption = "Fig.9") +
         xlab("Distance in Miles") +
         ylab("Median Rent in US-Dollars") +
         theme_bw(base_rect_size = 2) +
         theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

The graph clearly shows a distance-to-center gradient in price, but we make two observations. Firstly,  even though the general trend is downward sloping, there are many fluctuations inherent in the graph. These could either be wealthy neighbourhouds or a sign that Amsterdam is a rather "equal" city.

Secondly, most observations find themselves between 80-120$, a price difference that is not incredibly stark given that one apartment is in the heart of the center and another one is 6 miles away. This speaks for our comment that good public transport and an even demographic might attenuate the distance-to-center price gradient. 

To answer the question from previous section, we see why marriage and migration would not be as strong a predictor as we'd wish. This is because both are high in the whole central west of the city, but prices rather steadily, even if not strongly, decline. Additionally, there are also highly valued listings in the east of the city where marriage and migration rates are quite low, further attenuating the effect of migration and marriage on daily price.

Next to safety, connectivity and access to public transport is of great importance for tourist.


#### Infrastructure
To get from one attraction to the next, we usually can't get around public transportation. AirBnB property owners are aware of this fact and we assume that customers will have to pay a premium for good connectivity, or take a tradeoff on decrease daily price of property and decrease in connectivity.

We therefore engineered a variety of transportation data, including distance of the listing zipcode to the nearest major road and train station. We also included data on the distance of the listing zipcode to the nearest tourist attraction, museums, performing arts centers, and the number of cafes and restaurants per zipcode. 

The distance to tourist attractions, museum, and performing arts centers didn't show any significant correlation, implying that customers likely are not willing to pay up a premium to be close to these facilities. One reason could be that the transportation network in the city is so great that there might be no real need to be that close to these facilities, and that there are many transportation connections all around the city.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
maps[[2]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```

Indeed, Amsterdam has the second best urban public transport system in Europe according to a Bloomberg article (https://www.bloomberg.com/news/articles/2023-12-04/best-cities-for-transportation-public-transit-evs-cycling-networks).

This is corroborated by the average distance of a neighbourhood to what is considered a main road.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
maps[[2]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```

What about restaurants, cafes, and hotels?

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# 3 cafes 4 restaurants 5 hotels
maps[[3]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# 3 cafes 4 restaurants 5 hotels
maps[[4]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```
Restaurants and cafes are, as expected, concentrated around the central district. However, there are also districts in the mid-west and mid-east of the city that have high housing prices but also many restaurants and cafes.

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# 1 price
maps[[1]] +  labs(title = "Average Price", caption = "Fig.1") + 
             scale_fill_gradient(low = "white",high = airbnb_color, name = "Price Gradient in USD") +
             labs(title = "Avg. Daily AirBnB Price in Amsterdam", caption = "Fig.1")
```
This attenuates the strength of the predictors numbers of restaurants and cafes. Additionally, there are tracts with very high daily rates in the northwest of the city that only have very few restaurants.

In conclusion, engineering non-hedonic features has been quite demanding as so many factors seem to be well distributed in the city with low opportunities to find factors that clearly point to a price discrimination. This is a good sign as it implies that the city is rather equitable and internal factors of a house rather than demographics like migration influence housing prices.

### Preparation for Regression Model

```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Checking if we have too many categories in a variable

roomtype <- unique(listings$room_type)
length(roomtype)

property_type <- unique(listings$property_type)
length(property_type)

property_type <- unique(listings$property_type)
length(property_type)

sum(is.na(listings$square_feet))

listings <- listings %>% mutate(extra_people_is_cost = ifelse(listings$extra_people %in% c("$0.00"), "No", "Yes"))



variables_to_summarize <- c("room_type", "daily_price", "beds", "accommodates", "bed_type",
                            "bathrooms", "bedrooms", "amenities_count", "review_scores_rating", "property_type")


unique_values_df <- data.frame(Variable = character(), Unique_Values = integer(), stringsAsFactors = FALSE)


for (var in variables_to_summarize) {
  unique_values_df <- rbind(unique_values_df, data.frame(Variable = var, Unique_Values = length(unique(listings[[var]]))))
}


unique_values_df %>%
  kbl(caption = "Variable Values") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
In the last step of this section, we check whether we have some features that only have few unique factors. If so, this could become an issue when partitioning the data set into training and test data sets. We see that bed type, property type, and room type are candidates for potential trouble makers. We therefore checked for these rare values and filter them out in the first step in the methodology section.

In conclusion, the feature engineering section gives cues that good accessibility and a rather even price distribution throughout neighbourhoods, along with rather evenly spread demographics like sex crimes or number of cafes and restaurants speak for a rather equitable urban space in Amsterdam.





# Methods & Results

## Training Regression
```{r regression, results = 'hide', fig.align= 'center', warning = FALSE, message = FALSE, error = FALSE }
# Partitioning data set into training and test
set.seed(1000)

inTrain <- createDataPartition(
              y = paste(listings$daily_price,
                        listings$zipcode,
                        listings$neighbourhood),
              p = .6, list = FALSE)

# Filtering out factors in features that occur seldomly to avoid "new levels" error
listings_train <- listings[inTrain,] %>% filter(!room_type %in% c("Shared room"), !property_type %in% c("Boutique hotel", "Bungalow", "Cabin", "Chalet", "Nature lodge", "Villa", "Serviced apartment"), !bed_type %in% c("Airbed"))

listings_test <- listings[-inTrain,] %>% filter(!room_type %in% c("Shared room"), !property_type %in% c("Boutique hotel", "Bungalow", "Cabin", "Chalet", "Nature lodge", "Villa", "Serviced apartment"), !bed_type %in% c("Airbed"))

# Adding nearest neighbours
coords.test.training <-  st_coordinates(listings_train) 

neighborList.training <- knn2nb(knearneigh(coords.test.training, 1))

spatialWeights.training <- nb2listw(neighborList.training, style="W")


listings_train <- listings_train %>% mutate(k_nearest_price = lag.listw(spatialWeights.training, daily_price) / accommodates)

# Running regression
  reg_train <- 
    lm(daily_price ~ ., data = as.data.frame(listings_train) %>% 
                               dplyr::select(daily_price,
                                             room_type,
                                             near_ATTRAC,
                                             k_nearest_price,
                                             number_of_reviews,
                                             property_type,
                                             bathrooms,
                                             bedrooms,
                                             review_scores_rating,
                                             cancellation_policy,
                                             host_identity_verified,
                                             accommodates,
                                             beds,
                                             bed_type,
                                             host_is_superhost,
                                             cleaning_fee,
                                             security_deposit,
                                             extra_people,
                                             availability_30,
                                             zipcode,
                                             neighbourhood,
                                             distance))
  
summary(reg_train)$r.squared
```

```{r regression, results = 'hide', fig.align= 'center', warning = FALSE, message = FALSE, error = FALSE }
set.seed(1000)

loop <- c("daily_price", "room_type", "near_ATTRAC", "k_nearest_price", "number_of_reviews", "property_type", "bathrooms", "bedrooms", "review_scores_rating", "cancellation_policy", "host_identity_verified", "accommodates", "beds", "bed_type", "host_is_superhost", "cleaning_fee", "security_deposit", "extra_people", "availability_30", "zipcode", "neighbourhood", "distance")

results <- vector()

for (i in sequence(length(loop),1,1)) {
 words <- loop[1:i]  
 
 reg_train <- 
    lm(daily_price ~ ., data = as.data.frame(listings_train) %>% 
                               dplyr::select(words))
  
results [[i]] <- summary(reg_train)$r.squared
}

results <- as.data.frame(cbind(loop, results)) %>% mutate(lagged_results = lag(results), change = as.numeric(results) - as.numeric(lagged_results))
```

# Training Regression Results
```{r result_traiining_set, fig.align= 'center', warning = FALSE, message = FALSE, error = FALSE}
# Adding Baseline Regression predictions to data set and adding KPI's
listings_train <- listings_train %>% na.omit()

listings_train <-
  listings_train %>%
  mutate(Regression = "Baseline Regression",
         daily_price.predict = predict(reg_train, listings_train),
         daily_price.error = daily_price.predict - daily_price,
         daily_price.abserror = abs(daily_price.predict - daily_price),
         daily_price.ape = (abs(daily_price.predict - daily_price)) / daily_price.predict)%>%
  filter(!is.na(daily_price.abserror))


# Saving results in table 
results_train <- data.frame(MAE = mean(listings_train$daily_price.abserror, na.rm = T), MAPE =  mean(listings_train$daily_price.ape, na.rm = T))

results_train %>%
  kbl(caption = "Training Results") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

# Test Regression
```{r read_data, results = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Adding nearest neighbours
coords.test.2 <-  st_coordinates(listings_test) 

neighborList.test.2 <- knn2nb(knearneigh(coords.test.2, 3))

spatialWeights.test.2 <- nb2listw(neighborList.test.2, style="W")

listings_test <- listings_test %>% mutate(k_nearest_price = lag.listw(spatialWeights.test.2, daily_price) / accommodates)

# Applying regression model to test set and adding KPI's
listings_test <-
  listings_test %>%
  mutate(Regression = "Baseline Regression",
         daily_price.predict = predict(reg_train, listings_test),
         daily_price.error = daily_price.predict - daily_price,
         daily_price.abserror = abs(daily_price.predict - daily_price),
         daily_price.ape = (abs(daily_price.predict - daily_price)) / daily_price.predict)%>%
  filter(daily_price < 3000000, !is.na(daily_price.abserror))


# Saving results in table 
results_test <- data.frame(MAE = mean(listings_test$daily_price.abserror, na.rm = T), MAPE =  mean(listings_test$daily_price.ape, na.rm = T))

results_test %>%
  kbl(caption = "Test Results") %>%
  kable_classic(full_width = F, html_font = "Cambria")

# Visualizing spatial error
ggplot() +
  geom_sf(data = listings_test, fill ="grey40" ,colour = "white") +
  geom_sf(data = listings_test, aes(colour = q5(daily_price.error)),
          size = 1) +
  scale_colour_manual(values = palette6,
                      labels = qBr(listings_test, "daily_price.error"),
                      name = "Quintile \n Breaks")+
   labs(title = "daily_price Amsterdam") +
  mapTheme()
```


# Moran's I Test
```{r moran_mc, fig.align= 'center', warning = FALSE, message = FALSE, error = FALSE}
moranTest <- moran.mc(listings_test$daily_price.error, 
                      spatialWeights.test.2, nsim = 999)

morans_plot <-ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") +
  plotTheme()

morans_plot
```


## Cross-Validation
```{r result_cross_validation, results = 'hide', fig.align= 'center', warning = FALSE, message = FALSE, error = FALSE}
# Specifying 100-fold CV as computational nuance
fitControl <- trainControl(method = "cv", number = 100)

set.seed(825)

# Running 100-fold CV
reg.cv <- 
  train(daily_price ~ ., data = st_drop_geometry(listings_train) %>% 
                               dplyr::select(daily_price,
                                             room_type,
                                             near_ATTRAC,
                                             k_nearest_price,
                                             number_of_reviews,
                                             property_type,
                                             bathrooms,
                                             bedrooms,
                                             review_scores_rating,
                                             cancellation_policy,
                                             host_identity_verified,
                                             accommodates,
                                             beds,
                                             bed_type,
                                             host_is_superhost,
                                             cleaning_fee,
                                             security_deposit,
                                             extra_people,
                                             availability_30,
                                             zipcode,
                                             neighbourhood,
                                             distance), 
     method = "lm", trControl = fitControl, na.action = na.pass)

reg.cv$resample[1:100,]
```



```{r result_cross_validation_graph, fig.align= 'center', warning = FALSE, message = FALSE, error = FALSE}
ggplot(reg.cv$resample) +
  aes(MAE) +
  geom_histogram(bins=15)
```












